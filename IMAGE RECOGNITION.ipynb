{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Acer\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Found 300 images belonging to 5 classes.\n",
      "Found 100 images belonging to 5 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\Acer\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 138s 8s/step - loss: -15.0771 - accuracy: 0.2007 - val_loss: -6.9748 - val_accuracy: 0.1979\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 119s 7s/step - loss: -16.4382 - accuracy: 0.2042 - val_loss: -13.9496 - val_accuracy: 0.2143\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 123s 7s/step - loss: -15.4788 - accuracy: 0.1831 - val_loss: -9.9640 - val_accuracy: 0.2143\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 118s 7s/step - loss: -15.8704 - accuracy: 0.2153 - val_loss: -12.9532 - val_accuracy: 0.1548\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 103s 6s/step - loss: -15.7466 - accuracy: 0.2036 - val_loss: -6.9748 - val_accuracy: 0.2381\n"
     ]
    }
   ],
   "source": [
    "# importing libraries \n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense \n",
    "from keras import backend as K \n",
    "\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = 'C:\\\\Users\\\\Acer\\\\Desktop\\\\dataset_filtered\\\\data_train'\n",
    "validation_data_dir = 'C:\\\\Users\\\\Acer\\\\Desktop\\\\dataset_filtered\\\\data_test'\n",
    "nb_train_samples = 300\n",
    "nb_validation_samples = 100\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first': \n",
    "    input_shape = (3, img_width, img_height) \n",
    "else: \n",
    "    input_shape = (img_width, img_height, 3) \n",
    "\n",
    "model = Sequential() \n",
    "model.add(Conv2D(32, (2, 2), input_shape = input_shape)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
    "\n",
    "model.add(Conv2D(32, (2, 2))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
    "\n",
    "model.add(Conv2D(64, (2, 2))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size =(2, 2))) \n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(64)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(1)) \n",
    "model.add(Activation('sigmoid')) \n",
    "\n",
    "model.compile(loss ='binary_crossentropy', \n",
    "                    optimizer ='rmsprop', \n",
    "                metrics =['accuracy']) \n",
    "\n",
    "train_datagen = ImageDataGenerator( \n",
    "                rescale = 1. / 255, \n",
    "                shear_range = 0.2, \n",
    "                zoom_range = 0.2, \n",
    "            horizontal_flip = True) \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1. / 255) \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, \n",
    "                            target_size =(img_width, img_height), \n",
    "                    batch_size = batch_size, class_mode ='binary') \n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory( \n",
    "                                    validation_data_dir, \n",
    "                target_size =(img_width, img_height), \n",
    "        batch_size = batch_size, class_mode ='binary') \n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "    steps_per_epoch = nb_train_samples // batch_size, \n",
    "    epochs = epochs, validation_data = validation_generator, \n",
    "    validation_steps = nb_validation_samples // batch_size) \n",
    "\n",
    "model.save_weights('model_saved.h5') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model_in_json.json\", \"w\") as json_file:\n",
    "    json.dump(model_json, json_file)\n",
    "\n",
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "with open('model_in_json.json','r') as f:\n",
    "    model_json = json.load(f)\n",
    "\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[[1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "img = image.load_img('test1.jpg', target_size=(img_width, img_height))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "images = np.vstack([x])\n",
    "classes = model.predict_classes(images, batch_size=10)\n",
    "print (classes)\n",
    "\n",
    "img = image.load_img('test2.jpg', target_size=(img_width, img_height))\n",
    "y = image.img_to_array(img)\n",
    "y = np.expand_dims(y, axis=0)\n",
    "\n",
    "images = np.vstack([x, y])\n",
    "classes = model.predict_classes(images, batch_size=10)\n",
    "\n",
    "print (classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('test1.jpg', target_size=(img_width, img_height))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "images = np.vstack([x])\n",
    "classes = model.predict_classes(images, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amir khan': 0, 'deepika padukone': 1, 'hritik roshan': 2, 'shahrukh khan': 3, 'shruti hasan': 4}\n"
     ]
    }
   ],
   "source": [
    "classes = train_generator.class_indices    \n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
